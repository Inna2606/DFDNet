{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DFDNet Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tg-bomze/DFDNet/blob/whole/DFDNet_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRnUFdLSJ_WD",
        "colab_type": "text"
      },
      "source": [
        "<b><font color=\"black\" size=\"+4\">Portrait Enchancer</font></b>\n",
        "\n",
        "<b><font color=\"black\" size=\"+2\">Based on:</font></b>\n",
        "\n",
        "**GitHub repository**: [DFDNet](https://github.com/csxmli2016/DFDNet)\n",
        "\n",
        "Article: [Blind Face Restoration via Deep Multi-scale Component Dictionaries](https://arxiv.org/pdf/2008.00418.pdf)\n",
        "\n",
        "Creator: **[csxmli2016](https://github.com/csxmli2016).**\n",
        "\n",
        "<b><font color=\"black\" size=\"+2\">Colab created by:</font></b>\n",
        "\n",
        "GitHub: [@tg-bomze](https://github.com/tg-bomze),\n",
        "Telegram: [@bomze](https://t.me/bomze),\n",
        "Twitter: [@tg_bomze](https://twitter.com/tg_bomze).\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "```\n",
        "(ENG) To get started, click on the button (where the red arrow indicates). After clicking, wait until the execution is complete.\n",
        "```\n",
        "```\n",
        "(RUS) Чтобы начать, нажмите на кнопку (куда указывает красная стрелка), после чего дождитесь завершения выполнения блока.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GETEjyBz4cFj",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Clone Git repository and install all requirements</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Клонируем репозиторий и устанавливаем всё необходимое</font></b>\n",
        "\n",
        "!pip install dominate\n",
        "!pip install ffmpeg\n",
        "\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from IPython import display as ipythondisplay\n",
        "import moviepy.editor as mpy\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import ffmpeg\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "\n",
        "!rm -rf /content/sample_data\n",
        "!git clone https://github.com/tg-bomze/DFDNet.git\n",
        "\n",
        "!mkdir /content/DFDNet/checkpoints/\n",
        "!mkdir /content/DFDNet/checkpoints/facefh_dictionary\n",
        "!mkdir /content/DFDNet/weights/\n",
        "!mkdir /content/DFDNet/DictionaryCenter512/\n",
        "\n",
        "os.chdir('/content/DFDNet/FaceLandmarkDetection/')\n",
        "!python setup.py install\n",
        "os.chdir('/content/')\n",
        "clear_output()\n",
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E0pBF2tjnKr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Save the weights of the pretrained model and mount Google Drive</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Сохраняем веса предобученной модели на Гугл Диск</font></b>\n",
        "\n",
        "\n",
        "#@markdown **Follow this link: https://drive.google.com/drive/folders/1bayYIUMCSGmoFPyd4Uu2Uwn347RW-vl5**\n",
        "\n",
        "#@markdown <font color=\"red\">**1**</font>) right click on '**DFDNet**' (top center)\n",
        "\n",
        "#@markdown <font color=\"red\">**2**</font>) select '**Add shortcut to Drive**'\n",
        "\n",
        "#@markdown ![](https://raw.githubusercontent.com/tg-bomze/DFDNet/whole/shortcut.JPG)\n",
        "\n",
        "#@markdown <font color=\"red\">**3**</font>) **run this block and follow the further instructions**\n",
        "\n",
        "#@markdown *(ENG) Attention! If the weights have already been saved, then run this block and just mount Google Drive.*\n",
        "\n",
        "#@markdown *(RUS) Внимание! Если веса уже сохранены, то только запустите этот блок и смонтируйте Гугл Драйв.*\n",
        "\n",
        "print(\"(ENG) Follow the link below, select the account where you saved the pretrained model,\")\n",
        "print(\"click the 'Allow' button, copy authorization code in the field below and press Enter.\\n\")\n",
        "\n",
        "print(\"(RUS) Перейдите по ссылке ниже, выберите аккаунт, куда сохранили предобученную модель,\")\n",
        "print(\"нажмите на кнопку 'Разрешить', скопируйте авторизационный код в нижнее поле и нажмите Enter.\\n\")\n",
        "drive.mount('/content/drive')\n",
        "clear_output()\n",
        "print(\"0%/100%   Copying has started and will take about 4 minutes.\")\n",
        "!cp '/content/drive/My Drive/DFDNet/checkpoints/facefh_dictionary/latest_net_G.pth' '/content/DFDNet/checkpoints/facefh_dictionary'\n",
        "print(\"33%/100%  Checkpoints copied\")\n",
        "!cp '/content/drive/My Drive/DFDNet/weights/vgg19.pth' '/content/DFDNet/weights/'\n",
        "print(\"66%/100%  Weights copied\")\n",
        "!cp -r '/content/drive/My Drive/DFDNet/DictionaryCenter512/' '/content/DFDNet/'\n",
        "print(\"100%/100% Dictionary copied\")\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxGFpkPdT4Sr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Uploading a single face photo or video</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Загружаем фото или видео с одним лицом</font></b>\n",
        "\n",
        "os.chdir('/content/')\n",
        "!rm -rf /content/DFDNet/Results\n",
        "!rm -rf /content/DFDNet/TestData/TestWhole/*\n",
        "\n",
        "file_type = 'Photo' #@param [\"Photo\", \"Video\"]\n",
        "#@markdown ---\n",
        "if file_type == 'Photo':\n",
        "  uploaded = list(files.upload().keys())\n",
        "  if len(uploaded) > 1:\n",
        "    raise ValueError('You cannot upload more than one audio at a time!')\n",
        "  cont = uploaded[0]\n",
        "  CONTENT_FILENAME = \"content.\" + cont.split(\".\")[-1]\n",
        "  os.rename(cont, CONTENT_FILENAME)\n",
        "  content_path = \"/content/DFDNet/TestData/TestWhole/\" + CONTENT_FILENAME\n",
        "  !mv -f $CONTENT_FILENAME $content_path\n",
        "  clear_output()\n",
        "  try:\n",
        "    pil_content = Image.open(content_path)\n",
        "    (cont_width, cont_height) = pil_content.size\n",
        "    resize_cont = max(cont_width, cont_height)/256\n",
        "    display(pil_content.resize((int(cont_width/resize_cont), int(cont_height/resize_cont))))\n",
        "  except: print(\"Photo uploaded!\")\n",
        "else:\n",
        "  #@markdown **You can paste the YouTube link here:**\n",
        "  source_url = '' #@param {type:\"string\"}\n",
        "  if source_url == '':\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "      print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "          name=fn, length=len(uploaded[fn])))\n",
        "    file_name = \"/content/downloaded_video.\" + fn.split(\".\")[-1]\n",
        "    !mv -f $fn $file_name\n",
        "  else:\n",
        "    !pip install youtube_dl\n",
        "    import youtube_dl\n",
        "    try:\n",
        "      ydl_opts = {\n",
        "          'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "          'outtmpl': 'downloaded_video.mp4',\n",
        "          }\n",
        "      with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([source_url])\n",
        "      file_name = '/content/downloaded_video.mp4'\n",
        "    except BaseException:\n",
        "      !wget $source_url\n",
        "      fn = source_url.split('/')[-1]\n",
        "      file_name = \"/content/downloaded_video.\" + fn.split(\".\")[-1]\n",
        "      !mv -f $fn $file_name\n",
        "\n",
        "  #@markdown **Crop video (h:m:s)**\n",
        "  target_start = '00:00:00' #@param {type:\"string\"}\n",
        "  target_end = '00:00:00' #@param {type:\"string\"}\n",
        "  if target_end != '00:00:00':\n",
        "    new_file_name = 'new_target.' + file_name.split('.')[-1]\n",
        "    !ffmpeg -i $file_name -ss $target_start -to $target_end $new_file_name\n",
        "    !mv -f $new_file_name $file_name\n",
        "\n",
        "  !ffmpeg -y -i $file_name -vn -ar 44100 -ac 2 -ab 192K -f mp3 /content/sound.mp3\n",
        "\n",
        "  vidcap = cv2.VideoCapture(file_name)\n",
        "  success,image = vidcap.read()\n",
        "  count = 0\n",
        "  success = True\n",
        "  while success:\n",
        "    cv2.imwrite(\"/content/DFDNet/TestData/TestWhole/frame%09d.jpg\" % count, image)\n",
        "    success,image = vidcap.read()\n",
        "    count += 1\n",
        "\n",
        "  clear_output()\n",
        "  try:\n",
        "    fps_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FPS))\n",
        "    frames_of_video = int(cv2.VideoCapture(file_name).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(\"Video uploaded. Number of frames: {}. First frame:\\n\".format(str(frames_of_video)))\n",
        "  except: print(\"Video uploaded! First frame:\\n\")\n",
        "\n",
        "  pil_content = Image.open('/content/DFDNet/TestData/TestWhole/frame000000000.jpg')\n",
        "  (cont_width, cont_height) = pil_content.size\n",
        "  resize_cont = max(cont_width, cont_height)/256\n",
        "  display(pil_content.resize((int(cont_width/resize_cont), int(cont_height/resize_cont))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ7-E-vRSYar",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Start enchance</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Начать улучшение</font></b>\n",
        "\n",
        "%%time\n",
        "#@markdown **How many times to upscale the image?**\n",
        "upscale_factor = 1 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "os.chdir('/content/DFDNet/')\n",
        "!python test_FaceDict.py --test_path ./TestData/TestWhole --results_dir ./Results/TestWholeResults --upscale_factor $upscale_factor --gpu_ids 0\n",
        "clear_output()\n",
        "try: \n",
        "  enchance_face_path = '/content/DFDNet/Results/TestWholeResults/Step3_RestoreCropFace/' + CONTENT_FILENAME\n",
        "  pil_result = Image.open(enchance_face_path)\n",
        "  (res_width, res_height) = pil_result.size\n",
        "  resize_res = max(res_width, res_height)/256\n",
        "  display(pil_result.resize((int(res_width/resize_res), int(res_height/resize_res))))\n",
        "except: \n",
        "  print('Images enchanced')\n",
        "  enchance_face_path = '/content/DFDNet/Results/TestWholeResults/Step3_RestoreCropFace/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxBlGS4LW5LV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Upscaled and combine with the original image</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Объединяем с оригинальным изображением</font></b>\n",
        "\n",
        "%%time\n",
        "!rm -rf /content/DFDNet/Results/TestWholeResults/Step4_FinalResults\n",
        "print('\\n###############################################################################')\n",
        "print('############### Step 4: Paste the Restored Face to the Input Image ############')\n",
        "print('###############################################################################\\n')\n",
        "from data.image_folder import make_dataset\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "\n",
        "def reverse_align(input_path, face_path, param_path, save_path, upsample_scale=2):\n",
        "    out_size = (512, 512) \n",
        "    input_img = dlib.load_rgb_image(input_path)\n",
        "    h,w,_ = input_img.shape\n",
        "    face512 = dlib.load_rgb_image(face_path)\n",
        "    inv_M = np.loadtxt(param_path)\n",
        "    inv_crop_img = cv2.warpAffine(face512, inv_M, (w*upsample_scale,h*upsample_scale))\n",
        "    mask = np.ones((512, 512, 3), dtype=np.float32) #* 255\n",
        "    inv_mask = cv2.warpAffine(mask, inv_M, (w*upsample_scale,h*upsample_scale))\n",
        "    upsample_img = cv2.resize(input_img, (w*upsample_scale, h*upsample_scale))\n",
        "    inv_mask_erosion_removeborder = cv2.erode(inv_mask, np.ones((2 * upsample_scale, 2 * upsample_scale), np.uint8))# to remove the black border\n",
        "    inv_crop_img_removeborder = inv_mask_erosion_removeborder * inv_crop_img\n",
        "    total_face_area = np.sum(inv_mask_erosion_removeborder)//3\n",
        "    w_edge = int(total_face_area ** 0.5) // 20 #compute the fusion edge based on the area of face\n",
        "    erosion_radius = w_edge * 2\n",
        "    inv_mask_center = cv2.erode(inv_mask_erosion_removeborder, np.ones((erosion_radius, erosion_radius), np.uint8))\n",
        "    blur_size = w_edge * 2\n",
        "    inv_soft_mask = cv2.GaussianBlur(inv_mask_center,(blur_size + 1, blur_size + 1),0)\n",
        "    merge_img = inv_soft_mask * inv_crop_img_removeborder + (1 - inv_soft_mask) * upsample_img\n",
        "    io.imsave(save_path, merge_img.astype(np.uint8))\n",
        "\n",
        "TestImgPath = './TestData/TestWhole'\n",
        "ResultsDir = './Results/TestWholeResults'\n",
        "UpScaleWhole = upscale_factor\n",
        "SaveRestorePath = os.path.join(ResultsDir,'Step3_RestoreCropFace')# Only Face Results\n",
        "SaveFianlPath = os.path.join(ResultsDir,'Step4_FinalResults')\n",
        "SaveParamPath = os.path.join(ResultsDir,'Step1_AffineParam') #save the inverse affine parameters\n",
        "if not os.path.exists(SaveFianlPath):\n",
        "    os.makedirs(SaveFianlPath)\n",
        "ImgPaths = make_dataset(SaveRestorePath)\n",
        "for i,ImgPath in enumerate(ImgPaths):\n",
        "    ImgName = os.path.split(ImgPath)[-1]\n",
        "    print('Final Restoring {}'.format(ImgName))\n",
        "    WholeInputPath = os.path.join(TestImgPath,ImgName)\n",
        "    FaceResultPath = os.path.join(SaveRestorePath, ImgName)\n",
        "    ParamPath = os.path.join(SaveParamPath, ImgName+'.npy')\n",
        "    SaveWholePath = os.path.join(SaveFianlPath, ImgName)\n",
        "    reverse_align(WholeInputPath, FaceResultPath, ParamPath, SaveWholePath, UpScaleWhole)\n",
        "\n",
        "clear_output()\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y29LJCArrWk",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> View final result</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Посмотреть финальный результат</font></b>\n",
        "\n",
        "path_to_img = '/content/DFDNet/Results/TestWholeResults/Step4_FinalResults/'\n",
        "if len(os.listdir(path_to_img)) == 0:\n",
        "  path_to_img = '/content/DFDNet/Results/TestWholeResults/Step3_RestoreCropFace/'\n",
        "\n",
        "if file_type == 'Photo':\n",
        "  enchance_img_path = path_to_img + CONTENT_FILENAME\n",
        "  pil_result = Image.open(enchance_img_path)\n",
        "  (res_width, res_height) = pil_result.size\n",
        "  resize_res = max(res_width, res_height)/256\n",
        "  display(pil_result.resize((int(res_width/resize_res), int(res_height/resize_res))))\n",
        "else:\n",
        "  img = os.listdir(path_to_img)\n",
        "  img.sort()\n",
        "  staffs = []\n",
        "  for i in img:\n",
        "    staffs.append(path_to_img+i)\n",
        "\n",
        "  staff = cv2.imread(staffs[0])  # get size from the 1st frame\n",
        "  result_vid_path = '/content/output.mp4'\n",
        "  writer = cv2.VideoWriter(\n",
        "      result_vid_path,\n",
        "      cv2.VideoWriter_fourcc(*'MP4V'),\n",
        "      fps_of_video,\n",
        "      (staff.shape[1], staff.shape[0]),  # width, height\n",
        "      isColor=len(staff.shape) > 2)\n",
        "  for staff in map(cv2.imread, staffs):\n",
        "      writer.write(staff)\n",
        "  writer.release()\n",
        "\n",
        "  result_aud_path = result_vid_path.replace('.mp4', '-audio.mp4')\n",
        "  print('First frame:\\n')\n",
        "  try: \n",
        "    !ffmpeg -i /content/sound.mp3 -i $result_vid_path $result_aud_path\n",
        "    pil_result = Image.open('/content/DFDNet/Results/TestWholeResults/Step4_FinalResults/frame000000000.jpg')\n",
        "    (res_width, res_height) = pil_result.size\n",
        "    resize_res = max(res_width, res_height)/256\n",
        "    display(pil_result.resize((int(res_width/resize_res), int(res_height/resize_res))))\n",
        "  except:\n",
        "    pil_result = Image.open('/content/DFDNet/Results/TestWholeResults/Step3_RestoreCropFace/frame000000000.jpg')\n",
        "    (res_width, res_height) = pil_result.size\n",
        "    resize_res = max(res_width, res_height)/256\n",
        "    display(pil_result.resize((int(res_width/resize_res), int(res_height/resize_res))))\n",
        "  clear_output()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k-5a9RnV8-o",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title <b><font color=\"red\" size=\"+3\">←</font><font color=\"black\" size=\"+3\"> Downloading the final result</font></b>\n",
        "#@markdown <b><font color=\"black\" size=\"+1\"> (RUS) Скачать финальный результат (с аудио или без него)</font></b>\n",
        "if file_type == 'Photo':\n",
        "  files.download(enchance_img_path)\n",
        "else:\n",
        "  with_audio = False #@param {type:\"boolean\"}\n",
        "  if with_audio == True: files.download(result_aud_path)\n",
        "  else: files.download(result_vid_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}